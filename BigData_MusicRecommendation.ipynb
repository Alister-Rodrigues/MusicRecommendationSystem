{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOdFfd0tP-AW"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmH8UIabYo1m"
      },
      "source": [
        "#Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "garU6jRUZn5T"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sb\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOx0IBCDUBNA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKkQcVWm7t9x"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oyh4UgmZPM2"
      },
      "source": [
        "#Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlsDfVuwm4dr"
      },
      "source": [
        "file_song_data = \"/content/drive/MyDrive/Dataset/msdsummary.csv\"\n",
        "file_triplet_data = \"/content/drive/MyDrive/Dataset/kaggle_triplets.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjTcuWJBh_de"
      },
      "source": [
        "song_df = spark.read.csv(file_song_data, inferSchema=True, header=True, sep=',')\n",
        "song_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e86cDIVTiPqq"
      },
      "source": [
        "triplet_df = spark.read.csv('/content/drive/MyDrive/Dataset/kaggle_triplets.csv', inferSchema=True, header=True, sep=',')\n",
        "triplet_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGnHHCQJXwjC"
      },
      "source": [
        "#Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYZaSvzemH6k"
      },
      "source": [
        "MSD = triplet_df.join(song_df, triplet_df.song_id == song_df.song_id, how='left').drop(song_df.song_id)\n",
        "MSD.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk7AtvQ4pbsA"
      },
      "source": [
        "MSD = MSD['user_id', 'song_id', 'play_count', 'title', 'release', 'artist_name', 'year']\n",
        "MSD.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7FULwjMgtBW"
      },
      "source": [
        "print(MSD.count())\n",
        "print(MSD.select('user_id').distinct().count())\n",
        "print(MSD.select('song_id').distinct().count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syzsuANXgIoE"
      },
      "source": [
        "#MSD = MSD.limit(745976) #half of total samples\n",
        "#MSD = MSD.limit(372988) #1/4th of total samples\n",
        "#MSD = MSD.limit(186494) #1/8th of total samples\n",
        "#MSD = MSD.limit(93247) #1/16th of total samples\n",
        "MSD = MSD.limit(46623) #1/32 of total samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ1rTUboxyMk"
      },
      "source": [
        "print(MSD.count())\n",
        "print(MSD.select('user_id').distinct().count())\n",
        "print(MSD.select('song_id').distinct().count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3xkD_e2h_hE"
      },
      "source": [
        "#Queries for data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b951Yuhusooi"
      },
      "source": [
        "MSD.createOrReplaceTempView('playlist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38veYWda6Qct"
      },
      "source": [
        "query = \"SELECT artist_name, title, sum(play_count) AS number_of_total_play FROM playlist GROUP BY title, artist_name ORDER BY sum(play_count) DESC\"\n",
        "\n",
        "mostPlayedSongs = spark.sql(query)\n",
        "mostPlayedSongs.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GIHdlhzn8Hp"
      },
      "source": [
        "mostPlayedSongs = mostPlayedSongs.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYQEtgnCoKXP"
      },
      "source": [
        "mostPlayedSongs['song'] = mostPlayedSongs['title']+' - '+mostPlayedSongs['artist_name']\n",
        "mostPlayedSongs['index'] = mostPlayedSongs.index\n",
        "\n",
        "mostPlayedSongs_frames = mostPlayedSongs.iloc[:20, :]\n",
        "mostPlayedSongs_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm1-j9l_pgSm"
      },
      "source": [
        "bar_graph = sb.barplot(x='index', y='number_of_total_play', data=mostPlayedSongs_frames)\n",
        "bar_graph.set(xlabel='Song distribution', ylabel='Total Play Count', title='Most Played Songs (Top 20)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-guhGKQRSxZu"
      },
      "source": [
        "query = \"SELECT user_id, sum(play_count) AS number_of_total_play FROM playlist GROUP BY user_id ORDER BY sum(play_count)\"\n",
        "topListeners = spark.sql(query)\n",
        "topListeners.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHE0wyhgTpxT"
      },
      "source": [
        "query = \"SELECT play_count, count(*) AS count FROM playlist GROUP BY play_count ORDER BY play_count\"\n",
        "#This is supposed to be graphed but ok :|\n",
        "playDistribution = spark.sql(query)\n",
        "playDistribution.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka66_xpn2njQ"
      },
      "source": [
        "playDistribution = playDistribution.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWMOrsat4txb"
      },
      "source": [
        "playDistribution_frames = playDistribution.iloc[:20, :]\n",
        "playDistribution_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wo0gQf7-sGf"
      },
      "source": [
        "fig = px.pie(playDistribution_frames, values='count', names='play_count', hole=0.3, title='Play Count Distributions for the play_counts 1-20')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh4Met7TaAka"
      },
      "source": [
        "#10% of users from MSD data\n",
        "user = MSD.select('user_id').distinct()\n",
        "user1, user2 = user.randomSplit([0.5, 0.95], seed=123)\n",
        "userCount = user1.count()\n",
        "print(\"Users: \", userCount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dRKms9wfxgI"
      },
      "source": [
        "#Distinct list of songs\n",
        "songs = MSD.select('song_id').distinct()\n",
        "songCount = songs.count()\n",
        "print(\"Number of songs: \", songCount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaXylPq0gVSN"
      },
      "source": [
        "#making user ids into integers\n",
        "users_df = user1.withColumn('new_userid', monotonically_increasing_id())\n",
        "users_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q84hz0IJgxw6"
      },
      "source": [
        "#making song ids into integers\n",
        "song_df = songs.select('song_id', monotonically_increasing_id().alias('new_songid'))\n",
        "song_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbqpXrjzi8-K"
      },
      "source": [
        "#cross-join user and songs\n",
        "crossJoin = users_df.crossJoin(song_df)\n",
        "crossJoin.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrZX5c9djNVy"
      },
      "source": [
        "crossJoin.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MAxXdvKjVgr"
      },
      "source": [
        "df = crossJoin.join(MSD, ['user_id', 'song_id'], 'left').fillna(0)\n",
        "\n",
        "model_df = df.select(df.new_userid.cast('int'), df.new_songid.cast('int'),df.play_count.cast('int'))\n",
        "#cut this down in size. there isnt enough storage to train so much data\n",
        "\n",
        "\n",
        "(train_data, test_data) = model_df.select('new_userid', 'new_songid', 'play_count').randomSplit([0.7, 0.3], seed=12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o9kPk8BHglt"
      },
      "source": [
        "#Alternating Least Squares Algorithm (ALS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AoS6xc2kiLm"
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "als = ALS(userCol= 'new_userid',\n",
        "            itemCol= 'new_songid',\n",
        "            ratingCol= 'play_count',\n",
        "            rank= 10,\n",
        "            maxIter= 10,\n",
        "            alpha= 20,\n",
        "            regParam= .05,\n",
        "            coldStartStrategy= 'drop',\n",
        "            nonnegative= True,\n",
        "            implicitPrefs= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRXhUanNunIC"
      },
      "source": [
        "model = als.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7GXnL5y3jhE"
      },
      "source": [
        "#Rank Ordering Error Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4hb6NYSl-Tk"
      },
      "source": [
        "def ROEM(predictions, userCol='new_userid', itemCol='new_songid', ratingCol='play_count'):\n",
        "  predictions.createOrReplaceTempView('predictions')\n",
        "\n",
        "  denominator = predictions.groupBy().sum(ratingCol).collect()[0][0]\n",
        "\n",
        "  spark.sql(\"SELECT \" + userCol + \", \" + ratingCol + \", PERCENT_RANK() OVER (PARTITION BY \" + userCol + \" ORDER BY prediction DESC) AS rank FROM predictions\").createOrReplaceTempView('rankings')\n",
        "\n",
        "  numerator = spark.sql(\"SELECT SUM(\" + ratingCol + \" * rank) FROM rankings\").collect()[0][0]\n",
        "\n",
        "  performance = numerator/denominator\n",
        "  return performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2MeL-pmnnYK"
      },
      "source": [
        "predictions = model.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipYWhuCzr7z2"
      },
      "source": [
        "validation_performance = ROEM(predictions)\n",
        "print(validation_performance)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}